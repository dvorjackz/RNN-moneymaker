{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Moneymaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stock 3562/3563 (RDCM.txt)      \n",
      "Total number of stocks: 1187\n"
     ]
    }
   ],
   "source": [
    "raw_data = {}\n",
    "all_files = os.listdir(root_path)\n",
    "\n",
    "for i, filename in enumerate(all_files):\n",
    "    \n",
    "    # Only load 1/N of all stocks\n",
    "    if i % 3 == 0:\n",
    "    \n",
    "        len_stocks = len(all_files)\n",
    "        print(\"Loading stock {}/{} ({})   \".format(i + 1, len_stocks, filename), end='\\r')\n",
    "        \n",
    "        with open(root_path + filename) as f:\n",
    "            if not filename.startswith('.'):\n",
    "                data = json.load(f)\n",
    "                                \n",
    "                prices = []\n",
    "                dates = []\n",
    "                for k, v in data.items():\n",
    "                    prices.append(np.array([ float(i[1]) for i in v.items() if i[0] != \"5. volume\" ]))\n",
    "                    dates.append(k)\n",
    "                \n",
    "                # reverse so that data is increasing in time\n",
    "                prices.reverse()\n",
    "                dates.reverse()\n",
    "                raw_data[filename.split('.')[0]] = (prices, dates)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Total number of stocks: \" + str(len(raw_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to torch tensors...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = [], []\n",
    "y_train, y_val = [], []\n",
    "\n",
    "train_mean, val_mean = [], []\n",
    "train_std, val_std = [], []\n",
    "\n",
    "window_size = 122 # a third of a year\n",
    "\n",
    "plen = 0\n",
    "for i, items in enumerate(raw_data.items()):\n",
    "    print(\"({}/{})\".format(i, len(raw_data.items())), end=\"\\r\")\n",
    "    k, v = items\n",
    "    prices, _ = v\n",
    "    if len(prices) < window_size + 1:\n",
    "        continue\n",
    "    \n",
    "    prices = torch.tensor(prices).float()\n",
    "    \n",
    "    # used for validating that no data is missing\n",
    "    plen += prices.shape[0] - window_size - 1\n",
    "    \n",
    "    for j in range(prices.shape[0] - window_size - 1):\n",
    "        window = prices[j:j+window_size+1]     # window from 1st to 122nd and pred at 123rd\n",
    "        \n",
    "        mean = torch.mean(window)\n",
    "        std = torch.std(window)\n",
    "        \n",
    "        if std == 0:\n",
    "            break\n",
    "        \n",
    "        norm_window = (window - mean) / std\n",
    "        norm_x = norm_window[:window_size]\n",
    "        norm_y = norm_window[window_size][3]\n",
    "        \n",
    "        # 90% training to 10% validation\n",
    "        if i % 9 != 0:\n",
    "            X_train.append(norm_x.unsqueeze(0))\n",
    "            y_train.append(norm_y.item())\n",
    "            train_mean.append(mean)\n",
    "            train_std.append(std)\n",
    "        else:\n",
    "            X_val.append(norm_x.unsqueeze(0))\n",
    "            y_val.append(norm_y.item())\n",
    "            val_mean.append(mean)\n",
    "            val_std.append(std)\n",
    "\n",
    "print(\"Converting to torch tensors...\")\n",
    "X_train = torch.cat(X_train)\n",
    "y_train = torch.tensor(y_train).unsqueeze(1)\n",
    "X_val = torch.cat(X_val)\n",
    "y_val = torch.tensor(y_val).unsqueeze(1)\n",
    "\n",
    "train_mean = torch.tensor(train_mean)\n",
    "val_mean = torch.tensor(val_mean)\n",
    "train_std = torch.tensor(train_std)\n",
    "val_std = torch.tensor(val_std)\n",
    "\n",
    "# optimize for GPU if exists\n",
    "if torch.cuda.is_available():\n",
    "    X_train = X_train.cuda()\n",
    "    y_train = y_train.cuda()\n",
    "    X_val = X_val.cuda()\n",
    "    y_val = y_val.cuda()\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: \t\t torch.Size([2570550, 122, 4])\n",
      "X_val shape: \t\t torch.Size([299507, 122, 4])\n",
      "y_train shape: \t\t torch.Size([2570550, 1])\n",
      "y_val shape: \t\t torch.Size([299507, 1])\n",
      "\n",
      "train_mean shape: \t torch.Size([2570550])\n",
      "val_mean: \t\t torch.Size([299507])\n",
      "train_std: \t\t torch.Size([2570550])\n",
      "val_std: \t\t torch.Size([299507])\n",
      "\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \\t\\t\", X_train.shape)\n",
    "print(\"X_val shape: \\t\\t\", X_val.shape)\n",
    "print(\"y_train shape: \\t\\t\", y_train.shape)\n",
    "print(\"y_val shape: \\t\\t\", y_val.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"train_mean shape: \\t\", train_mean.shape)\n",
    "print(\"val_mean: \\t\\t\", val_mean.shape)\n",
    "print(\"train_std: \\t\\t\", train_std.shape)\n",
    "print(\"val_std: \\t\\t\", val_std.shape)\n",
    "print(\"\")\n",
    "\n",
    "# # false means that something is wrong\n",
    "# print(plen == X_train.shape[0] + X_val.shape[0])\n",
    "# print(plen == y_train.shape[0] + y_val.shape[0])\n",
    "# print(plen == train_mean.shape[0] + val_mean.shape[0])\n",
    "# print(plen == train_std.shape[0] + val_mean.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2570550])\n"
     ]
    }
   ],
   "source": [
    "# a = torch.sum(torch.sum(X_train.cpu() == X_train.cpu(), dim=1), dim=1) != 0\n",
    "# print(a.shape)\n",
    "# b = (y_train.cpu() == y_train.cpu()) != 0\n",
    "\n",
    "# c = a if torch.sum(a) < torch.sum(b) else b\n",
    "\n",
    "# X = X[c]\n",
    "# y = y[c]\n",
    "\n",
    "# print(\"new:\")\n",
    "# print(X.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = Dataset(X_train, y_train)\n",
    "loader = DataLoader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, h=None):\n",
    "        if type(h) == type(None):\n",
    "            out, hn = self.rnn(x)\n",
    "        else:\n",
    "            out, hn = self.rnn(x, h.detach())\n",
    "        out = self.drop(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 4\n",
    "hidden_dim = 20\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNClassifier(input_dim, hidden_dim, output_dim)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "    \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs = []\n",
    "val_accs = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pre-existing model for further training or prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNClassifier(input_dim, hidden_dim, output_dim)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "checkpoint = torch.load('assets/partial_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.910 \t val loss: 2.022\n",
      "training loss: 0.075 \t val loss: 0.194\n",
      "training loss: 0.212 \t val loss: 0.170\n",
      "training loss: 0.143 \t val loss: 0.166\n",
      "training loss: 0.354 \t val loss: 0.167\n",
      "training loss: 0.135 \t val loss: 0.153\n",
      "training loss: 0.011 \t val loss: 0.156\n",
      "training loss: 0.135 \t val loss: 0.178\n",
      "training loss: 0.497 \t val loss: 0.154\n",
      "training loss: 0.033 \t val loss: 0.151\n",
      "training loss: 0.048 \t val loss: 0.155\n",
      "training loss: 0.236 \t val loss: 0.149\n",
      "training loss: 0.054 \t val loss: 0.153\n",
      "training loss: 0.108 \t val loss: 0.154\n",
      "training loss: 0.386 \t val loss: 0.153\n",
      "training loss: 0.222 \t val loss: 0.167\n",
      "training loss: 0.248 \t val loss: 0.153\n",
      "16562/2570550\r"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "num_epochs = 3\n",
    "for ep in range(num_epochs):\n",
    "    tstart = time.time()\n",
    "    for i, data in enumerate(loader):\n",
    "        model.train()\n",
    "        print(\"{}/{}\".format(i, X_train.shape[0]), end='\\r')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data[0])\n",
    "        loss = criterion(outputs, data[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if i % 1000 == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                train_losses.append(loss.item())\n",
    "                pXval = model(X_val)\n",
    "                vloss = criterion(pXval, y_val)\n",
    "                val_losses.append(vloss.item())\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                }, 'assets/partial_model.pt')\n",
    "\n",
    "                print(\"training loss: {:<3.3f} \\t val loss: {:<3.3f}\".format(loss, vloss))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        pXval = model(X_val)\n",
    "        vloss = criterion(pXval, y_val)\n",
    "        val_losses.append(vloss.item())\n",
    "        epoch += 1    \n",
    "        tend = time.time()\n",
    "        print('epoch: {:<3d} \\t time: {:<3.2f} \\t val loss: {:<3.3f}'.format(epoch, \n",
    "                tend - tstart, vloss.item()))\n",
    "time_total = time.time() - t0\n",
    "print('Total time: {:4.3f}, average time per epoch: {:4.3f}'.format(time_total, time_total / num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the UserWarning\n",
    "torch.save(model, 'assets/model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('assets/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_losses = [i for i in train_losses if i < 4000]\n",
    "plt.plot(t_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title('loss history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')\n",
    "plt.legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(X_val)\n",
    "print(criterion(pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predictions compared to standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch_size = 1000\n",
    "val_set_size = X_val.shape[0]\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(0, val_set_size, val_batch_size):\n",
    "        start = i\n",
    "        end = min(i+val_batch_size, val_set_size)\n",
    "        print(\"Predicting {} - {}...\".format(start, end), end='\\r')\n",
    "        preds.append(model(X_val[start:end]))\n",
    "pred = torch.cat(preds, dim=0).cpu()\n",
    "print(\"\")\n",
    "plt.plot((pred - y_val.cpu()).detach()[1000:1100])\n",
    "plt.title('std difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predictions compared to actual price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_abs = pred * X_std[val_selector][:,:,3] + X_mean[val_selector][:,:,3]\n",
    "y_val_abs = y_val * X_std[val_selector][:,:,3] + X_mean[val_selector][:,:,3]\n",
    "\n",
    "plt.plot((pred_abs - y_val_abs).detach()[1000:1100])\n",
    "plt.title('absolute price difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and visualizing random stock in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_names_and_dates = np.array(name_and_date)[val_selector]\n",
    "\n",
    "stock = \"AUTO\";\n",
    "stock_selector = torch.tensor(val_names_and_dates[:,0] == (stock + \".txt\"))\n",
    "\n",
    "s_pred_abs = pred_abs[stock_selector]\n",
    "s_y_val_abs = y_val_abs[stock_selector]\n",
    "\n",
    "stock_dates = val_names_and_dates[stock_selector][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dates.sort()\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(stock_dates[10:20], s_pred_abs.detach()[10:20])\n",
    "ax.plot(stock_dates[10:20], s_y_val_abs.detach()[10:20])\n",
    "fig.autofmt_xdate()\n",
    "start, end = ax.get_xlim()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing random unseen stock (skipped over in the data loading stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = []\n",
    "test_y = []\n",
    "test_name_and_date = []\n",
    "window_size = 122\n",
    "\n",
    "with open(root_path + \"AAPL.txt\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    temp1 = [] # for prices\n",
    "    temp2 = [] # for name and date\n",
    "\n",
    "    for k, v in data.items():\n",
    "        temp1.append(torch.tensor([ float(i[1]) for i in v.items() if i[0] != \"5. volume\" ]).unsqueeze(0))\n",
    "        temp2.append(k)\n",
    "\n",
    "    # reverse so that data is increasing in time\n",
    "    temp1.reverse()\n",
    "    temp2.reverse()\n",
    "\n",
    "    prices = torch.cat(temp1, 0)\n",
    "\n",
    "    for i in range(len(prices) - window_size - 1):\n",
    "        seq.append(prices[i:i+window_size].unsqueeze(0))\n",
    "        test_y.append(prices[i+window_size][3].item()) # predict the closing price\n",
    "        test_name_and_date.append(['AAPL', temp2[i + window_size + 1]])\n",
    "        \n",
    "test_X = torch.cat(seq, 0)\n",
    "test_y = torch.tensor(test_y).unsqueeze(1) # from (N,) to (N,1)\n",
    "\n",
    "test_X_mean = torch.mean(test_X, dim=1).unsqueeze(1)\n",
    "test_X_std = torch.std(test_X, dim=1).unsqueeze(1)\n",
    "\n",
    "test_X = (test_X - test_X_mean) / test_X_std\n",
    "test_y = (test_y - test_X_mean[:,:,3]) / test_X_std[:,:,3]\n",
    "\n",
    "test_pred = model(test_X)\n",
    "print(criterion(test_pred, test_y))\n",
    "\n",
    "test_pred = test_pred * test_X_std[:,:,3] + test_X_mean[:,:,3]\n",
    "test_y = test_y * test_X_std[:,:,3] + test_X_mean[:,:,3]\n",
    "\n",
    "plt.plot(test_pred.detach()[3000:3100])\n",
    "plt.plot(test_y[3000:3100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [i[1] for i in test_name_and_date]\n",
    "print(dates)\n",
    "temp_pred = [ i.data[0] for i in test_pred.detach().numpy() ]\n",
    "temp_y = [ i.data[0] for i in test_y.detach().numpy() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(dates[1000:1010], temp_pred[1000:1010])\n",
    "fig.autofmt_xdate()\n",
    "start, end = ax.get_xlim()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(dates[1000:1010], temp_y[1000:1010])\n",
    "fig.autofmt_xdate()\n",
    "start, end = ax.get_xlim()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
